{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bafb515b",
   "metadata": {},
   "source": [
    "# Document Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bc22e2-63a0-4a2a-bcaf-54786597b821",
   "metadata": {},
   "source": [
    "The steps in this notebook include: \n",
    "- **Use Langchain Document Splitters** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813cce6e-ac18-46a8-a497-0e91211e68f7",
   "metadata": {},
   "source": [
    "## Contents\n",
    "1. [Installation](#installation)\n",
    "2. [CharacterTextSplitter vs RecursiveCharacterTextSplitte](#vs)\n",
    "3. [Recursive Text Splitter](#recursivetextsplitter)  \n",
    "4. [Token splitting](#token)\n",
    "5. [Context aware splitting](#context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb8698a-f38e-4526-ab55-7898efa001dd",
   "metadata": {},
   "source": [
    "**Source:** https://learn.deeplearning.ai/langchain-chat-with-your-data/lesson/3/document-splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bc0bd0-35fd-4533-9c90-25fde4070159",
   "metadata": {},
   "source": [
    "![overview.png](./images/overview.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6903fedf-75ac-415e-b7f5-a60092502b53",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52b22d8-9f39-4df9-be1e-4599d8202f10",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **Installation** <a name=\"installation\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c676ac50-02e1-4ae1-94b7-afee0b62f675",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U langchain openai python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6650e62-3701-4f14-aedd-cbb36f73806d",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f9ad2a1-2c8e-471e-8174-338cf2e3e92d",
   "metadata": {
    "height": 166,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import sys\n",
    "\n",
    "sys.path.append('../..')\n",
    "\n",
    "# Load from a .env file \n",
    "#from dotenv import load_dotenv, find_dotenv\n",
    "#_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = \"eyJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJhcHAiLCJzdWIiOiIxNDYyNzU5IiwiYXVkIjoiV0VCIiwiaWF0IjoxNjk5NDUxNzMzLCJleHAiOjE3MDAwNTY1MzN9.7mqcOZ3w4gd7m9QGWcdOx7U1ayk1l22LNZ8LfPOLqjE\"\n",
    "\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113914c6-6349-4c7f-a11d-3c3506f54840",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513be9d3-b292-44fb-90a5-f330c8f2c77f",
   "metadata": {},
   "source": [
    "# **CharacterTextSplitter vs RecursiveCharacterTextSplitter** <a name=\"vs\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06ea702c",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c17b092-6ed9-4470-9a62-6bc2b01cfa1f",
   "metadata": {},
   "source": [
    "**Parameters:**  \n",
    "- `chunk_size`: Maximum size of chunks to return\n",
    "- `chunk_overlap`: Overlap in characters between chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d587fb0",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [],
   "source": [
    "chunk_size =26\n",
    "chunk_overlap = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2723bf02",
   "metadata": {
    "height": 149,
    "tags": []
   },
   "outputs": [],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap\n",
    ")\n",
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61167fc",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd21401b",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abcdefghijklmnopqrstuvwxyz']\n",
      "['abcdefghijklmnopqrstuvwxyz']\n"
     ]
    }
   ],
   "source": [
    "text1 = 'abcdefghijklmnopqrstuvwxyz'\n",
    "print(len(text1))\n",
    "\n",
    "print(r_splitter.split_text(text1))\n",
    "print(c_splitter.split_text(text1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b5da0f9",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "['abcdefghijklmnopqrstuvwxyz', 'wxyzabcdefg']\n",
      "['abcdefghijklmnopqrstuvwxyzabcdefg']\n"
     ]
    }
   ],
   "source": [
    "text2 = 'abcdefghijklmnopqrstuvwxyzabcdefg'\n",
    "print(len(text2))\n",
    "\n",
    "print(r_splitter.split_text(text2))\n",
    "print(c_splitter.split_text(text2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8aab77-7b85-4759-aa9c-73f13528e51c",
   "metadata": {},
   "source": [
    "- `RecursiveCharacterTextSplitter` or `CharacterTextSplitter` don't split the string `text1` because its length is less than 26 (`chunk size`)  \n",
    "- `CharacterTextSplitter` don't split the string `text2` because the default separator value is `separator: str = '\\n\\n'`, so it don't split the string. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51500f4-d714-4b6d-8b19-439ff5fe52cb",
   "metadata": {},
   "source": [
    "<img src=\"images/chunk_overlap.png\" width=500 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dce39d64",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n",
      "['a b c d e f g h i j k l m', 'l m n o p q r s t u v w x', 'w x y z']\n",
      "['a b c d e f g h i j k l m n o p q r s t u v w x y z']\n"
     ]
    }
   ],
   "source": [
    "text3 = \"a b c d e f g h i j k l m n o p q r s t u v w x y z\"\n",
    "print(len(text3))\n",
    "\n",
    "print(r_splitter.split_text(text3))\n",
    "print(c_splitter.split_text(text3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227d6f1f-db3a-4352-8ebc-489b792a77ef",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bb3a3f-f88b-463d-8f8e-312c73271888",
   "metadata": {},
   "source": [
    "By using a new `separator` for the `CharacterTextSplitter`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63e71644",
   "metadata": {
    "height": 115,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a b c d e f g h i j k l m', 'l m n o p q r s t u v w x', 'w x y z']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    "    separator = ' ',\n",
    ")\n",
    "c_splitter.split_text(text3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4014aa-ca0b-4817-b4f6-113ec11ff576",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a4d0ed",
   "metadata": {},
   "source": [
    "# **Recursive Text Splitter** <a name=\"recursivetextsplitter\"></a>\n",
    "\n",
    "`RecursiveCharacterTextSplitter` is recommended for generic text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96926a42-92e6-4ad4-9946-908a075fb32d",
   "metadata": {
    "height": 132,
    "tags": []
   },
   "outputs": [],
   "source": [
    "some_text = \"\"\"When writing documents, writers will use document structure to group content. \\\n",
    "This can convey to the reader, which idea's are related. For example, closely related ideas \\\n",
    "are in sentances. Similar ideas are in paragraphs. Paragraphs form a document. \\n\\n  \\\n",
    "Paragraphs are often delimited with a carriage return or two carriage returns. \\\n",
    "Carriage returns are the \"backslash n\" you see embedded in this string. \\\n",
    "Sentences have a period at the end, but also, have a space.\\\n",
    "and words are separated by space.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18706d73",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "496"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5083a172-ba0a-4d9f-b561-18f0d2e6d9ce",
   "metadata": {
    "height": 183,
    "tags": []
   },
   "outputs": [],
   "source": [
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=450,\n",
    "    chunk_overlap=0,\n",
    "    separator = ' '\n",
    ")\n",
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=450,\n",
    "    chunk_overlap=0, \n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f8aa4ed-5347-4819-b3c1-d15696832a65",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['When writing documents, writers will use document structure to group content. This can convey to the reader, which idea\\'s are related. For example, closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document. \\n\\n Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this string. Sentences have a period at the end, but also,',\n",
       " 'have a space.and words are separated by space.']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6af907f2-4110-4e40-a831-593f8592bd83",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"When writing documents, writers will use document structure to group content. This can convey to the reader, which idea's are related. For example, closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document.\",\n",
       " 'Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this string. Sentences have a period at the end, but also, have a space.and words are separated by space.']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6270a2da-d9b5-436e-8ff4-5382065536c8",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> üí°<b>Separators:</b>\n",
    "<ul>\n",
    "    <li><code>CharacterTextSplitter</code> need an unique <i>string</i> as separator. <code>separator: str = '\\n\\n'</code>  \n",
    "    <li><code>RecursiveCharacterTextSplitter</code> can take mulitple <i>string</i> as separators (<i>list</i>). <code>Optional[List[str]]</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e2366b-c53e-4321-8d6a-53c446cd5241",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3720ef-2a97-4e0f-a2da-660b274b2f00",
   "metadata": {
    "tags": []
   },
   "source": [
    "Let's reduce the chunk size a bit and add a period to our separators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d99ab0e6-725d-45e5-8a8a-86a22d2358ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"When writing documents, writers will use document structure to group content. This can convey to the reader, which idea's are related. For example,\",\n",
       " 'closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document.',\n",
       " 'Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this',\n",
       " 'string. Sentences have a period at the end, but also, have a space.and words are separated by space.']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=150,\n",
    "    chunk_overlap=0,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"\\. \", \" \", \"\"]\n",
    ")\n",
    "r_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31da7561",
   "metadata": {
    "height": 115,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"When writing documents, writers will use document structure to group content. This can convey to the reader, which idea's are related. For example,\",\n",
       " 'closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document.',\n",
       " 'Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this',\n",
       " 'string. Sentences have a period at the end, but also, have a space.and words are separated by space.']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=150,\n",
    "    chunk_overlap=0,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"(?<=\\. )\", \" \", \"\"]\n",
    ")\n",
    "r_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf351e3-d1c8-45b8-a040-17a843ef8943",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a4f5a2-e602-4b8c-a371-98b5b41e98d5",
   "metadata": {},
   "source": [
    "**Load PDF file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a469e07d",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[Document(page_content='MachineLearning-Lecture01  \\nInstructor (Andrew Ng):  Okay. Good morning. Welcome to CS229, the machine \\nlearning class. So what I wanna do today is ju st spend a little time going over the logistics \\nof the class, and then we\\'ll start to  talk a bit about machine learning.  \\nBy way of introduction, my name\\'s  Andrew Ng and I\\'ll be instru ctor for this class. And so \\nI personally work in machine learning, and I\\' ve worked on it for about 15 years now, and \\nI actually think that machine learning is th e most exciting field of all the computer \\nsciences. So I\\'m actually always excited about  teaching this class. Sometimes I actually \\nthink that machine learning is not only the most exciting thin g in computer science, but \\nthe most exciting thing in all of human e ndeavor, so maybe a little bias there.  \\nI also want to introduce the TAs, who are all graduate students doing research in or \\nrelated to the machine learni ng and all aspects of machin e learning. Paul Baumstarck \\nworks in machine learning and computer vision.  Catie Chang is actually a neuroscientist \\nwho applies machine learning algorithms to try to understand the human brain. Tom Do \\nis another PhD student, works in computa tional biology and in sort of the basic \\nfundamentals of human learning. Zico Kolter is  the head TA ‚Äî he\\'s head TA two years \\nin a row now ‚Äî works in machine learning a nd applies them to a bunch of robots. And \\nDaniel Ramage is ‚Äî I guess he\\'s not here  ‚Äî Daniel applies l earning algorithms to \\nproblems in natural language processing.  \\nSo you\\'ll get to know the TAs and me much be tter throughout this quarter, but just from \\nthe sorts of things the TA\\'s do, I hope you can  already tell that machine learning is a \\nhighly interdisciplinary topic in which just the TAs find l earning algorithms to problems \\nin computer vision and biology and robots a nd language. And machine learning is one of \\nthose things that has and is having a large impact on many applications.  \\nSo just in my own daily work, I actually frequently end up talking to people like \\nhelicopter pilots to biologists to people in  computer systems or databases to economists \\nand sort of also an unending stream of  people from industry coming to Stanford \\ninterested in applying machine learni ng methods to their own problems.  \\nSo yeah, this is fun. A couple of weeks ago, a student actually forwar ded to me an article \\nin \"Computer World\" about the 12 IT skills th at employers can\\'t say no to. So it\\'s about \\nsort of the 12 most desirabl e skills in all of IT and all of information technology, and \\ntopping the list was actually machine lear ning. So I think this is a good time to be \\nlearning this stuff and learning algorithms and having a large impact on many segments \\nof science and industry.  \\nI\\'m actually curious about something. Learni ng algorithms is one of the things that \\ntouches many areas of science and industrie s, and I\\'m just kind of curious. How many \\npeople here are computer science majors, are in the computer science department? Okay. \\nAbout half of you. How many people are from  EE? Oh, okay, maybe about a fifth. How ', metadata={'source': 'data/MachineLearning-Lecture01.pdf', 'page': 0})]\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"data/MachineLearning-Lecture01.pdf\")\n",
    "pages = loader.load()\n",
    "\n",
    "print(type(pages))\n",
    "print(pages[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bba6f05d",
   "metadata": {
    "height": 132,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=150,\n",
    "    length_function=len\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c752a663-896b-4a24-9ffb-7640642b7a3f",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "docs = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc0cbae-cec0-4f7f-a9de-2698864713e6",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> üí°<b>Split documents:</b>\n",
    "<code>split_documents(documents: Iterable[Document]) ‚Üí List[Document]</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7474a52c",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77\n",
      "985\n",
      "page_content=\"MachineLearning-Lecture01  \\nInstructor (Andrew Ng):  Okay. Good morning. Welcome to CS229, the machine \\nlearning class. So what I wanna do today is ju st spend a little time going over the logistics \\nof the class, and then we'll start to  talk a bit about machine learning.  \\nBy way of introduction, my name's  Andrew Ng and I'll be instru ctor for this class. And so \\nI personally work in machine learning, and I' ve worked on it for about 15 years now, and \\nI actually think that machine learning is th e most exciting field of all the computer \\nsciences. So I'm actually always excited about  teaching this class. Sometimes I actually \\nthink that machine learning is not only the most exciting thin g in computer science, but \\nthe most exciting thing in all of human e ndeavor, so maybe a little bias there.  \\nI also want to introduce the TAs, who are all graduate students doing research in or \\nrelated to the machine learni ng and all aspects of machin e learning. Paul Baumstarck\" metadata={'source': 'data/MachineLearning-Lecture01.pdf', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "print(len(docs))\n",
    "print(len(docs[0].page_content))\n",
    "\n",
    "print(docs[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d16046b2",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3011e311-584e-4310-a193-2094031e3ebd",
   "metadata": {},
   "source": [
    "We have **22 pages** in our PDF. With the Text splitter, we have splitted the `Document` into **77 chunks** where each `page_content`'s length is <1000 (`chunk_size`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd5c55b-730b-4a7f-89c3-466bcf7ecdfd",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da44add5-3624-4aa0-ac52-2a2d3d2dbf23",
   "metadata": {},
   "source": [
    "**Load Notion zip file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aa7f6c22-c131-4c16-82b5-7a7f9d2e2a17",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  data/27261042-ae4b-4a74-b2d7-6154d7246eb4_Export-0d6d611c-c647-4296-b0f6-4c989f8c5d0d.zip\n",
      "  inflating: data/Notion_DB/MLOps tools 2023 830865f5e014447eb4c8c2cf5dbb7367.md  \n"
     ]
    }
   ],
   "source": [
    "!unzip -o \"data/27261042-ae4b-4a74-b2d7-6154d7246eb4_Export-0d6d611c-c647-4296-b0f6-4c989f8c5d0d.zip\" -d \"data/Notion_DB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3a9e741c",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='# MLOps tools 2023\\n\\n[https://i0.wp.com/neptune.ai/wp-content/uploads/2023/07/MLOps-Landscape-in-2023-Top-Tools-and-Platforms-5.png?ssl=1](https://i0.wp.com/neptune.ai/wp-content/uploads/2023/07/MLOps-Landscape-in-2023-Top-Tools-and-Platforms-5.png?ssl=1)\\n\\n![https://i0.wp.com/neptune.ai/wp-content/uploads/2023/07/MLOps-Landscape-in-2023-Top-Tools-and-Platforms-5.png?ssl=1](https://i0.wp.com/neptune.ai/wp-content/uploads/2023/07/MLOps-Landscape-in-2023-Top-Tools-and-Platforms-5.png?ssl=1)', metadata={'source': 'data/Notion_DB/MLOps tools 2023 830865f5e014447eb4c8c2cf5dbb7367.md'})]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import NotionDirectoryLoader\n",
    "loader = NotionDirectoryLoader(\"data/Notion_DB\")\n",
    "notion_db = loader.load()\n",
    "notion_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d30861d0-4370-49c1-a6fc-a924f9a171ee",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "docs = text_splitter.split_documents(notion_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "39a59ff8",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(notion_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "73411cbd",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2912871b-7c44-4c3c-80ce-459e0ab718fc",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f720db",
   "metadata": {},
   "source": [
    "# **Token splitting** <a name=\"token\"></a>\n",
    "\n",
    "We can also split on token count explicity, if we want.\n",
    "\n",
    "This can be useful because LLMs often have context windows designated in **tokens**.\n",
    "\n",
    "Tokens are often ~4 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "840fde9b-1e8f-404e-903a-6c999d380c7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\n",
      "  Obtaining dependency information for tiktoken from https://files.pythonhosted.org/packages/f4/2e/0adf6e264b996e263b1c57cad6560ffd5492a69beb9fd779ed0463d486bc/tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tiktoken) (2023.6.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2023.5.7)\n",
      "Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tiktoken\n",
      "Successfully installed tiktoken-0.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -U tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "da0bcc05",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['foo', ' bar', ' b', 'az', 'zy', 'foo']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import TokenTextSplitter\n",
    "\n",
    "text_splitter = TokenTextSplitter(chunk_size=1, chunk_overlap=0)\n",
    "\n",
    "text1 = \"foo bar bazzyfoo\"\n",
    "\n",
    "text_splitter.split_text(text1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3a3db1-9a5a-498e-a922-dd55a8ed817f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> üí° <b>Token splitter:</b>\n",
    "     \n",
    "<code>TokenTextSplitter</code> splits a raw text string to tokens using <i>model tokenizer</i>. By first converting the text into <b>BPE tokens</b>, then split these tokens into chunks and convert the tokens within a single chunk back into text.\n",
    "<ul>\n",
    "    <li> Uses the OpenAI language model to split text into fragments based on tokens. By default it uses <code>encoding_name: str = 'gpt2</code>.\n",
    "    <li> <b>Byte-Pair Encoding (BPE)</b> was initially developed as an algorithm to compress texts, and then used by OpenAI for tokenization when pretraining the GPT model. It‚Äôs used by a lot of Transformer models, including GPT, GPT-2, RoBERTa, BART, and DeBERTa. <a href=https://huggingface.co/learn/nlp-course/chapter6/5?fw=pt#byte-pair-encoding-tokenization>More</a>.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ffa29d43",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_splitter = TokenTextSplitter(chunk_size=10, chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e53e203a",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='MachineLearning-Lecture01  \\n', metadata={'source': 'data/MachineLearning-Lecture01.pdf', 'page': 0})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = text_splitter.split_documents(pages)\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "917f7abc",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'data/MachineLearning-Lecture01.pdf', 'page': 0}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4826d02-470b-434b-95c5-b76ef281e312",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282d9bfa",
   "metadata": {},
   "source": [
    "# **Context aware splitting** <a name=\"context\"></a>\n",
    "\n",
    "Chunking aims to keep text with common context together.\n",
    "\n",
    "A text splitting often uses sentences or other delimiters to keep related text together but many documents (such as Markdown) have structure (headers) that can be explicitly used in splitting.\n",
    "\n",
    "We can use `MarkdownHeaderTextSplitter` to preserve header metadata in our chunks, as show below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "aa3b93d9",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import NotionDirectoryLoader\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f84d41-3264-4654-8c74-e50ca9990dc9",
   "metadata": {},
   "source": [
    "**Parameters:** \n",
    "- `headers_to_split_on` _List[Tuple[str, str]]_ ‚Äì Headers we want to track\n",
    "- `return_each_line` _bool_ ‚Äì Return each line w/ associated headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d2c73a9c",
   "metadata": {
    "height": 132,
    "tags": []
   },
   "outputs": [],
   "source": [
    "markdown_document = \"\"\"# Title\\n\\n \\\n",
    "## Chapter 1\\n\\n \\\n",
    "Hi this is Jim\\n\\n Hi this is Joe\\n\\n \\\n",
    "### Section \\n\\n \\\n",
    "Hi this is Lance \\n\\n \n",
    "## Chapter 2\\n\\n \\\n",
    "Hi this is Molly\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "eadb7740",
   "metadata": {
    "height": 98,
    "tags": []
   },
   "outputs": [],
   "source": [
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a789eede",
   "metadata": {
    "height": 81,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[Document(page_content='Hi this is Jim  \\nHi this is Joe', metadata={'Header 1': 'Title', 'Header 2': 'Chapter 1'}), Document(page_content='Hi this is Lance', metadata={'Header 1': 'Title', 'Header 2': 'Chapter 1', 'Header 3': 'Section'}), Document(page_content='Hi this is Molly', metadata={'Header 1': 'Title', 'Header 2': 'Chapter 2'})]\n",
      "\n",
      "page_content='Hi this is Jim  \\nHi this is Joe' metadata={'Header 1': 'Title', 'Header 2': 'Chapter 1'}\n",
      "page_content='Hi this is Lance' metadata={'Header 1': 'Title', 'Header 2': 'Chapter 1', 'Header 3': 'Section'}\n"
     ]
    }
   ],
   "source": [
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on,\n",
    "    return_each_line=False\n",
    ")\n",
    "md_header_splits = markdown_splitter.split_text(markdown_document)\n",
    "\n",
    "print(len(md_header_splits))\n",
    "print(md_header_splits)\n",
    "print()\n",
    "print(md_header_splits[0])\n",
    "print(md_header_splits[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "63f07c3b-9c6b-4f00-b52c-5c1ef133589e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "[Document(page_content='Hi this is Jim', metadata={'Header 1': 'Title', 'Header 2': 'Chapter 1'}), Document(page_content='Hi this is Joe', metadata={'Header 1': 'Title', 'Header 2': 'Chapter 1'}), Document(page_content='Hi this is Lance', metadata={'Header 1': 'Title', 'Header 2': 'Chapter 1', 'Header 3': 'Section'}), Document(page_content='Hi this is Molly', metadata={'Header 1': 'Title', 'Header 2': 'Chapter 2'})]\n",
      "\n",
      "page_content='Hi this is Jim' metadata={'Header 1': 'Title', 'Header 2': 'Chapter 1'}\n",
      "page_content='Hi this is Joe' metadata={'Header 1': 'Title', 'Header 2': 'Chapter 1'}\n"
     ]
    }
   ],
   "source": [
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on,\n",
    "    return_each_line=True\n",
    ")\n",
    "md_header_splits = markdown_splitter.split_text(markdown_document)\n",
    "\n",
    "print(len(md_header_splits))\n",
    "print(md_header_splits)\n",
    "print()\n",
    "print(md_header_splits[0])\n",
    "print(md_header_splits[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3db322d-5d27-4a35-b297-199393c33c0c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"> üí° <b>Markdown splitter:</b>\n",
    "\n",
    "<code>return_each_line</code>: Output line-by-line instead of aggregated into chunks with common headers\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58db353-76b2-4fae-9936-be15f8e7a646",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0c6111",
   "metadata": {},
   "source": [
    "Try on a real Markdown file, like a Notion database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b238b16f",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [],
   "source": [
    "loader = NotionDirectoryLoader(\"data/Notion_DB\")\n",
    "docs = loader.load()\n",
    "txt = ' '.join([d.page_content for d in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9fdab1d4",
   "metadata": {
    "height": 132,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='[https://i0.wp.com/neptune.ai/wp-content/uploads/2023/07/MLOps-Landscape-in-2023-Top-Tools-and-Platforms-5.png?ssl=1](https://i0.wp.com/neptune.ai/wp-content/uploads/2023/07/MLOps-Landscape-in-2023-Top-Tools-and-Platforms-5.png?ssl=1)  \\n![https://i0.wp.com/neptune.ai/wp-content/uploads/2023/07/MLOps-Landscape-in-2023-Top-Tools-and-Platforms-5.png?ssl=1](https://i0.wp.com/neptune.ai/wp-content/uploads/2023/07/MLOps-Landscape-in-2023-Top-Tools-and-Platforms-5.png?ssl=1)', metadata={'Header 1': 'MLOps tools 2023'})]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "]\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on\n",
    ")\n",
    "\n",
    "md_header_splits = markdown_splitter.split_text(txt)\n",
    "\n",
    "md_header_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb23de3-4338-4fdc-bc51-d5ddad96bba8",
   "metadata": {
    "height": 30
   },
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
